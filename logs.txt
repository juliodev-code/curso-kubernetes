* 
* ==> Audit <==
* |---------|--------------------------------|----------|-----------------------|---------|---------------------|---------------------|
| Command |              Args              | Profile  |         User          | Version |     Start Time      |      End Time       |
|---------|--------------------------------|----------|-----------------------|---------|---------------------|---------------------|
| start   | --driver=hyperv                | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:12 CST |                     |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:15 CST |                     |
| start   | --driver=hyperv                | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:16 CST |                     |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:17 CST |                     |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:18 CST |                     |
|         | --no-vtx-check                 |          |                       |         |                     |                     |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:19 CST |                     |
|         | --no-vtx-check                 |          |                       |         |                     |                     |
| delete  |                                | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:20 CST | 13 Jul 23 22:20 CST |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:20 CST |                     |
|         | --no-vtx-check                 |          |                       |         |                     |                     |
| delete  |                                | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:24 CST | 13 Jul 23 22:24 CST |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 13 Jul 23 22:24 CST |                     |
|         | --no-vtx-check                 |          |                       |         |                     |                     |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 17 Jul 23 20:46 CST |                     |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 17 Jul 23 20:51 CST | 17 Jul 23 20:53 CST |
| stop    |                                | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 17 Jul 23 21:24 CST | 17 Jul 23 21:25 CST |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 27 Jul 23 21:21 CST | 27 Jul 23 21:25 CST |
| start   | --driver=virtualbox            | minikube | DESKTOP-M1QPO5D\jcjar | v1.30.1 | 28 Jul 23 20:46 CST |                     |
|---------|--------------------------------|----------|-----------------------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/07/28 20:46:38
Running on machine: DESKTOP-M1QPO5D
Binary: Built with gc go1.20.2 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0728 20:46:38.190864   14168 out.go:296] Setting OutFile to fd 84 ...
I0728 20:46:38.191851   14168 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0728 20:46:38.191851   14168 out.go:309] Setting ErrFile to fd 88...
I0728 20:46:38.191851   14168 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0728 20:46:38.214865   14168 out.go:303] Setting JSON to false
I0728 20:46:38.218861   14168 start.go:125] hostinfo: {"hostname":"DESKTOP-M1QPO5D","uptime":257593,"bootTime":1690341204,"procs":245,"os":"windows","platform":"Microsoft Windows 10 Home","platformFamily":"Standalone Workstation","platformVersion":"10.0.19045.3208 Build 19045.3208","kernelVersion":"10.0.19045.3208 Build 19045.3208","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"57ff4839-8a51-418e-99fe-1d8d95d2acae"}
W0728 20:46:38.218861   14168 start.go:133] gopshost.Virtualization returned error: not implemented yet
I0728 20:46:38.219859   14168 out.go:177] * minikube v1.30.1 on Microsoft Windows 10 Home 10.0.19045.3208 Build 19045.3208
I0728 20:46:38.220868   14168 notify.go:220] Checking for updates...
I0728 20:46:38.221869   14168 config.go:182] Loaded profile config "minikube": Driver=virtualbox, ContainerRuntime=docker, KubernetesVersion=v1.26.3
I0728 20:46:38.221869   14168 driver.go:375] Setting default libvirt URI to qemu:///system
I0728 20:46:38.256085   14168 virtualbox.go:136] virtual box version: 7.0.10r158379
I0728 20:46:38.256647   14168 out.go:177] * Using the virtualbox driver based on existing profile
I0728 20:46:38.257182   14168 start.go:295] selected driver: virtualbox
I0728 20:46:38.257182   14168 start.go:870] validating driver "virtualbox" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.30.1-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:3900 CPUs:2 DiskSize:20000 VMDriver: Driver:virtualbox HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:true DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\jcjar:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0728 20:46:38.257182   14168 start.go:881] status for virtualbox: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:7.0.10r158379
}
I0728 20:46:38.297557   14168 cni.go:84] Creating CNI manager for ""
I0728 20:46:38.297557   14168 cni.go:157] "virtualbox" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0728 20:46:38.297557   14168 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.30.1-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:3900 CPUs:2 DiskSize:20000 VMDriver: Driver:virtualbox HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:true DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\jcjar:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0728 20:46:38.298093   14168 iso.go:125] acquiring lock: {Name:mkb935ae16f2c0e59c8c4eef00e6015cfab4f555 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0728 20:46:38.299163   14168 out.go:177] * Starting control plane node minikube in cluster minikube
I0728 20:46:38.299687   14168 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0728 20:46:38.300225   14168 preload.go:148] Found local preload: C:\Users\jcjar\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4
I0728 20:46:38.300760   14168 cache.go:57] Caching tarball of preloaded images
I0728 20:46:38.300760   14168 preload.go:174] Found C:\Users\jcjar\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0728 20:46:38.300760   14168 cache.go:60] Finished verifying existence of preloaded tar for  v1.26.3 on docker
I0728 20:46:38.300760   14168 profile.go:148] Saving config to C:\Users\jcjar\.minikube\profiles\minikube\config.json ...
I0728 20:46:38.302478   14168 cache.go:193] Successfully downloaded all kic artifacts
I0728 20:46:38.303003   14168 start.go:364] acquiring machines lock for minikube: {Name:mke91c9c34e17b28cd9fd022fb34b09a9f090f11 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I0728 20:46:38.303003   14168 start.go:368] acquired machines lock for "minikube" in 0s
I0728 20:46:38.303003   14168 start.go:96] Skipping create...Using existing machine configuration
I0728 20:46:38.303003   14168 fix.go:55] fixHost starting: 
I0728 20:46:38.303523   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:38.724312   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="saved"
VMStateChangeTime="2023-07-28T04:27:03.000000000"
VMStateFile="C:\Users\jcjar\.minikube\machines\minikube\minikube\Snapshots\2023-07-28T04-26-52-882903000Z.sav"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
}
I0728 20:46:38.724312   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:38.724312   14168 fix.go:103] recreateIfNeeded on minikube: state=Saved err=<nil>
W0728 20:46:38.724312   14168 fix.go:129] unexpected machine state, will restart: <nil>
I0728 20:46:38.725559   14168 out.go:177] * Restarting existing virtualbox VM for "minikube" ...
I0728 20:46:38.726646   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:38.785391   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="saved"
VMStateChangeTime="2023-07-28T04:27:03.000000000"
VMStateFile="C:\Users\jcjar\.minikube\machines\minikube\minikube\Snapshots\2023-07-28T04-26-52-882903000Z.sav"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
}
I0728 20:46:38.785391   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:38.785954   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe modifyvm minikube --natpf1 delete ssh
I0728 20:46:38.831841   14168 main.go:141] libmachine: STDOUT:
{
}
I0728 20:46:38.831841   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:38.831841   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe modifyvm minikube --natpf1 ssh,tcp,127.0.0.1,50078,,22
I0728 20:46:38.879372   14168 main.go:141] libmachine: STDOUT:
{
}
I0728 20:46:38.879372   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:38.879372   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe startvm minikube --type headless
I0728 20:46:50.299334   14168 main.go:141] libmachine: STDOUT:
{
Waiting for VM "minikube" to power on...
VM "minikube" has been successfully started.
}
I0728 20:46:50.299334   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:50.299334   14168 main.go:141] libmachine: Waiting for an IP...
I0728 20:46:50.299334   14168 main.go:141] libmachine: Getting to WaitForSSH function...
I0728 20:46:50.302367   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:50.305377   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:50.305377   14168 main.go:141] libmachine: About to run SSH command:
exit 0
I0728 20:46:56.899691   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0728 20:46:56.899691   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:56.968237   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:56.968237   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:56.968237   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.016399   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.016399   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.016399   14168 main.go:141] libmachine: Host-only MAC: 0800274c6846

I0728 20:46:57.019303   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:57.020281   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:57.020281   14168 main.go:141] libmachine: About to run SSH command:
ip addr show
I0728 20:46:57.124376   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86399sec preferred_lft 86399sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 599sec preferred_lft 599sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

I0728 20:46:57.124376   14168 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86399sec preferred_lft 86399sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 599sec preferred_lft 599sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

END SSH

I0728 20:46:57.124376   14168 main.go:141] libmachine: IP is 192.168.59.100
I0728 20:46:57.124376   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.173137   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.173137   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.173137   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.223575   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.223575   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.223575   14168 main.go:141] libmachine: Host-only MAC: 0800274c6846

I0728 20:46:57.226506   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:57.227484   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:57.227484   14168 main.go:141] libmachine: About to run SSH command:
ip addr show
I0728 20:46:57.329273   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86398sec preferred_lft 86398sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 598sec preferred_lft 598sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

I0728 20:46:57.329273   14168 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86398sec preferred_lft 86398sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 598sec preferred_lft 598sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

END SSH

I0728 20:46:57.330888   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.378901   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.378901   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.378901   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.437622   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.437622   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.438282   14168 main.go:141] libmachine: Host-only MAC: 0800274c6846

I0728 20:46:57.441360   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:57.442091   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:57.442091   14168 main.go:141] libmachine: About to run SSH command:
ip addr show
I0728 20:46:57.549741   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86398sec preferred_lft 86398sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 598sec preferred_lft 598sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

I0728 20:46:57.549741   14168 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86398sec preferred_lft 86398sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 598sec preferred_lft 598sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

END SSH

I0728 20:46:57.549741   14168 profile.go:148] Saving config to C:\Users\jcjar\.minikube\profiles\minikube\config.json ...
I0728 20:46:57.552668   14168 machine.go:88] provisioning docker machine ...
I0728 20:46:57.552668   14168 buildroot.go:166] provisioning hostname "minikube"
I0728 20:46:57.554619   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:57.555597   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:57.555597   14168 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0728 20:46:57.703732   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0728 20:46:57.706661   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:57.706661   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:57.706661   14168 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0728 20:46:57.800648   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0728 20:46:57.800648   14168 buildroot.go:172] set auth options {CertDir:C:\Users\jcjar\.minikube CaCertPath:C:\Users\jcjar\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\jcjar\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\jcjar\.minikube\machines\server.pem ServerKeyPath:C:\Users\jcjar\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\jcjar\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\jcjar\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\jcjar\.minikube}
I0728 20:46:57.800648   14168 buildroot.go:174] setting up certificates
I0728 20:46:57.800648   14168 provision.go:83] configureAuth start
I0728 20:46:57.800648   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.851048   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.851048   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.851048   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:57.901865   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:57.901865   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:57.901865   14168 main.go:141] libmachine: Host-only MAC: 0800274c6846

I0728 20:46:57.904027   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:57.904563   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:57.904563   14168 main.go:141] libmachine: About to run SSH command:
ip addr show
I0728 20:46:58.017059   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86398sec preferred_lft 86398sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 598sec preferred_lft 598sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

I0728 20:46:58.017059   14168 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86398sec preferred_lft 86398sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 598sec preferred_lft 598sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

END SSH

I0728 20:46:58.017059   14168 provision.go:138] copyHostCerts
I0728 20:46:58.018660   14168 exec_runner.go:144] found C:\Users\jcjar\.minikube/ca.pem, removing ...
I0728 20:46:58.018660   14168 exec_runner.go:207] rm: C:\Users\jcjar\.minikube\ca.pem
I0728 20:46:58.019209   14168 exec_runner.go:151] cp: C:\Users\jcjar\.minikube\certs\ca.pem --> C:\Users\jcjar\.minikube/ca.pem (1074 bytes)
I0728 20:46:58.021354   14168 exec_runner.go:144] found C:\Users\jcjar\.minikube/cert.pem, removing ...
I0728 20:46:58.021354   14168 exec_runner.go:207] rm: C:\Users\jcjar\.minikube\cert.pem
I0728 20:46:58.021354   14168 exec_runner.go:151] cp: C:\Users\jcjar\.minikube\certs\cert.pem --> C:\Users\jcjar\.minikube/cert.pem (1119 bytes)
I0728 20:46:58.023378   14168 exec_runner.go:144] found C:\Users\jcjar\.minikube/key.pem, removing ...
I0728 20:46:58.023378   14168 exec_runner.go:207] rm: C:\Users\jcjar\.minikube\key.pem
I0728 20:46:58.023378   14168 exec_runner.go:151] cp: C:\Users\jcjar\.minikube\certs\key.pem --> C:\Users\jcjar\.minikube/key.pem (1675 bytes)
I0728 20:46:58.024354   14168 provision.go:112] generating server cert: C:\Users\jcjar\.minikube\machines\server.pem ca-key=C:\Users\jcjar\.minikube\certs\ca.pem private-key=C:\Users\jcjar\.minikube\certs\ca-key.pem org=jcjar.minikube san=[192.168.59.100 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0728 20:46:58.357216   14168 provision.go:172] copyRemoteCerts
I0728 20:46:58.366213   14168 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0728 20:46:58.366213   14168 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50078 SSHKeyPath:C:\Users\jcjar\.minikube\machines\minikube\id_rsa Username:docker}
I0728 20:46:58.428017   14168 ssh_runner.go:362] scp C:\Users\jcjar\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1074 bytes)
I0728 20:46:58.476015   14168 ssh_runner.go:362] scp C:\Users\jcjar\.minikube\machines\server.pem --> /etc/docker/server.pem (1196 bytes)
I0728 20:46:58.518163   14168 ssh_runner.go:362] scp C:\Users\jcjar\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0728 20:46:58.557253   14168 provision.go:86] duration metric: configureAuth took 756.6048ms
I0728 20:46:58.557253   14168 buildroot.go:189] setting minikube options for container-runtime
I0728 20:46:58.557792   14168 config.go:182] Loaded profile config "minikube": Driver=virtualbox, ContainerRuntime=docker, KubernetesVersion=v1.26.3
I0728 20:46:58.560575   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:58.561123   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:58.561123   14168 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0728 20:46:58.653590   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: tmpfs

I0728 20:46:58.653590   14168 buildroot.go:70] root file system type: tmpfs
I0728 20:46:58.653590   14168 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0728 20:46:58.656521   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:58.656521   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:58.656521   14168 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=virtualbox --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0728 20:46:58.781944   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=virtualbox --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0728 20:46:58.784609   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:58.784620   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:58.784620   14168 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0728 20:46:58.898872   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0728 20:46:58.898872   14168 machine.go:91] provisioned docker machine in 1.3462036s
I0728 20:46:58.898872   14168 start.go:300] post-start starting for "minikube" (driver="virtualbox")
I0728 20:46:58.898872   14168 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0728 20:46:58.906683   14168 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0728 20:46:58.906683   14168 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50078 SSHKeyPath:C:\Users\jcjar\.minikube\machines\minikube\id_rsa Username:docker}
I0728 20:46:59.031184   14168 ssh_runner.go:195] Run: cat /etc/os-release
I0728 20:46:59.037043   14168 info.go:137] Remote host: Buildroot 2021.02.12
I0728 20:46:59.037043   14168 filesync.go:126] Scanning C:\Users\jcjar\.minikube\addons for local assets ...
I0728 20:46:59.037043   14168 filesync.go:126] Scanning C:\Users\jcjar\.minikube\files for local assets ...
I0728 20:46:59.037043   14168 start.go:303] post-start completed in 138.1713ms
I0728 20:46:59.037043   14168 fix.go:57] fixHost completed within 20.7340399s
I0728 20:46:59.052667   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:59.053642   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:59.053642   14168 main.go:141] libmachine: About to run SSH command:
date +%!s(MISSING).%!N(MISSING)
I0728 20:46:59.155091   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 1690598818.685740811

I0728 20:46:59.155091   14168 fix.go:207] guest clock: 1690598818.685740811
I0728 20:46:59.155091   14168 fix.go:220] Guest: 2023-07-28 20:46:58.685740811 -0600 CST Remote: 2023-07-28 20:46:59.0370438 -0600 CST m=+20.922300601 (delta=-351.302989ms)
I0728 20:46:59.155091   14168 fix.go:191] guest clock delta is within tolerance: -351.302989ms
I0728 20:46:59.155091   14168 start.go:83] releasing machines lock for "minikube", held for 20.8520872s
I0728 20:46:59.155091   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:59.207264   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:59.207264   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:59.207264   14168 main.go:141] libmachine: COMMAND: C:\Program Files\Oracle\VirtualBox\VBoxManage.exe showvminfo minikube --machinereadable
I0728 20:46:59.255114   14168 main.go:141] libmachine: STDOUT:
{
name="minikube"
Encryption:     disabled
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
CfgFile="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.vbox"
SnapFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Snapshots"
LogFldr="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\Logs"
hardwareuuid="0cf3560a-6eb0-44c0-8f15-6d92b5a619d9"
memory=3900
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
BIOS NVRAM File="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2023-07-29T02:46:50.284000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\boot2docker.iso"
"SATA-ImageUUID-0-0"="beeb8c0a-e0eb-4dbe-aeb1-fed0e95c7c3b"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\disk.vmdk"
"SATA-ImageUUID-1-0"="3dc31d12-2ea9-4215-9c0c-c4e6ed04fed6"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027A6B680"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,50078,,22"
hostonlyadapter2="VirtualBox Host-Only Ethernet Adapter #2"
macaddress2="0800274C6846"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="c/Users"
SharedFolderPathMachineMapping1="\\\\?\\c:\\Users"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_audio_enabled="off"
rec_screen_dest="File"
rec_screen_dest_filename="C:\\Users\\jcjar\\.minikube\\machines\\minikube\\minikube\\minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1690514502837
GuestAdditionsFacility_VirtualBox System Service=50,1690514503373
GuestAdditionsFacility_Seamless Mode=0,1690598810158
GuestAdditionsFacility_Graphics Mode=0,1690598810158
}
I0728 20:46:59.255114   14168 main.go:141] libmachine: STDERR:
{
}
I0728 20:46:59.255689   14168 main.go:141] libmachine: Host-only MAC: 0800274c6846

I0728 20:46:59.257728   14168 main.go:141] libmachine: Using SSH client type: native
I0728 20:46:59.257728   14168 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x5a8640] 0x5ab500 <nil>  [] 0s} 127.0.0.1 50078 <nil> <nil>}
I0728 20:46:59.258706   14168 main.go:141] libmachine: About to run SSH command:
ip addr show
I0728 20:46:59.367864   14168 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86396sec preferred_lft 86396sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 596sec preferred_lft 596sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

I0728 20:46:59.368409   14168 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:a6:b6:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86396sec preferred_lft 86396sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:4c:68:46 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 596sec preferred_lft 596sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:2a:67:cb:eb brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
6: bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 0e:6a:49:a7:b3:e7 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.1/16 brd 10.244.255.255 scope global bridge
       valid_lft forever preferred_lft forever
7: vethbdfc28ba@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:37:2a:4d:83:76 brd ff:ff:ff:ff:ff:ff link-netnsid 0
8: veth4d77afa5@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master bridge state UP group default 
    link/ether 7e:79:8c:03:4b:b0 brd ff:ff:ff:ff:ff:ff link-netnsid 1

END SSH

I0728 20:46:59.371427   14168 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0728 20:46:59.371427   14168 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50078 SSHKeyPath:C:\Users\jcjar\.minikube\machines\minikube\id_rsa Username:docker}
I0728 20:46:59.382740   14168 ssh_runner.go:195] Run: cat /version.json
I0728 20:46:59.382740   14168 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:50078 SSHKeyPath:C:\Users\jcjar\.minikube\machines\minikube\id_rsa Username:docker}
I0728 20:47:01.551716   14168 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (2.1802892s)
W0728 20:47:01.551716   14168 start.go:830] [curl -sS -m 2 https://registry.k8s.io/] failed: curl -sS -m 2 https://registry.k8s.io/: Process exited with status 28
stdout:

stderr:
curl: (28) Resolving timed out after 2000 milliseconds
I0728 20:47:01.551716   14168 ssh_runner.go:235] Completed: cat /version.json: (2.1689764s)
W0728 20:47:01.551716   14168 out.go:239] ! This VM is having trouble accessing https://registry.k8s.io
W0728 20:47:01.552395   14168 out.go:239] * To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
I0728 20:47:01.569957   14168 ssh_runner.go:195] Run: systemctl --version
I0728 20:47:01.598083   14168 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
W0728 20:47:01.609728   14168 cni.go:208] loopback cni configuration skipped: "/etc/cni/net.d/*loopback.conf*" not found
I0728 20:47:01.617672   14168 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0728 20:47:01.639144   14168 cni.go:258] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0728 20:47:01.639144   14168 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0728 20:47:01.643748   14168 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0728 20:47:01.783641   14168 docker.go:639] Got preloaded images: -- stdout --
mysql:8
registry.k8s.io/kube-apiserver:v1.26.3
registry.k8s.io/kube-scheduler:v1.26.3
registry.k8s.io/kube-controller-manager:v1.26.3
registry.k8s.io/kube-proxy:v1.26.3
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0728 20:47:01.783641   14168 docker.go:569] Images already preloaded, skipping extraction
I0728 20:47:01.783641   14168 start.go:481] detecting cgroup driver to use...
I0728 20:47:01.783641   14168 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0728 20:47:01.825034   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0728 20:47:01.854395   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0728 20:47:01.890714   14168 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0728 20:47:01.901682   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0728 20:47:01.981100   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0728 20:47:02.013148   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0728 20:47:02.045663   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0728 20:47:02.068122   14168 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0728 20:47:02.103727   14168 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0728 20:47:02.136509   14168 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0728 20:47:02.164584   14168 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0728 20:47:02.193005   14168 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0728 20:47:02.463835   14168 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0728 20:47:02.581918   14168 start.go:481] detecting cgroup driver to use...
I0728 20:47:02.590704   14168 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0728 20:47:02.638697   14168 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0728 20:47:02.675911   14168 ssh_runner.go:195] Run: sudo systemctl stop -f containerd
I0728 20:47:02.737614   14168 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0728 20:47:02.782030   14168 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0728 20:47:02.798213   14168 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0728 20:47:02.825624   14168 ssh_runner.go:195] Run: which cri-dockerd
I0728 20:47:02.846701   14168 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0728 20:47:02.882837   14168 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0728 20:47:02.936293   14168 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0728 20:47:03.109925   14168 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0728 20:47:03.324039   14168 docker.go:538] configuring docker to use "cgroupfs" as cgroup driver...
I0728 20:47:03.324039   14168 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0728 20:47:03.365176   14168 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0728 20:47:03.582328   14168 ssh_runner.go:195] Run: sudo systemctl restart docker
I0728 20:53:18.669798   14168 ssh_runner.go:235] Completed: sudo systemctl restart docker: (6m15.0874698s)
I0728 20:53:18.670341   14168 out.go:177] 
W0728 20:53:18.670884   14168 out.go:239] X Exiting due to RUNTIME_ENABLE: Failed to enable container runtime: sudo systemctl restart docker: Process exited with status 1
stdout:

stderr:
Job for docker.service failed because the control process exited with error code.
See "systemctl status docker.service" and "journalctl -xe" for details.

W0728 20:53:18.671446   14168 out.go:239] * 
W0728 20:53:18.672082   14168 out.go:239] ╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯
I0728 20:53:18.673472   14168 out.go:177] 

* 
* ==> Docker <==
* -- Journal begins at Fri 2023-07-28 03:21:43 UTC, ends at Sat 2023-07-29 02:54:09 UTC. --
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/79b68e1ba8f842abb0e36a6ac958f32ce801847beaa536dcc6b7556871b04e64/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/a00e7d17af5e8cc1776e10bf0663c539a2b843b469fff7e4db3cd56259f2c184/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e186b4a454e08293197d935aad51aa1028214aea00cf57fd1a96c2844966a46c/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.183925100Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.183977198Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.183989771Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.183998558Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/120804b94f851f363dcffa0ba9fbd37cc575cd5c76b3e211ca39ea943b2625cd/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/ba2115d33ee772cc4d83c51430d66bbd6c01b1e0cacb76d638cb82feed8db6da/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.403101519Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.403513202Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.404880396Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.406689831Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.623605499Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.623659911Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.623678396Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.623689526Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/925d7899fb55bd8a4a96f7de4ab972817597677298d7b566394dca7d83d7ddbc/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.726121065Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.726173243Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.726193451Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.726202417Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube cri-dockerd[1151]: time="2023-07-29T02:53:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/b6764787cbbdfc0f156a2dfb9089d80268b1f59eca75fb3c9926437d8c5f35ae/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.949813616Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.950051542Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.950111475Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:26 minikube dockerd[54451]: time="2023-07-29T02:53:26.950155838Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:27 minikube cri-dockerd[1151]: time="2023-07-29T02:53:27Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/c85398f0f502376fc71d430016a626025c21930cbef587b86ac007236a8564e8/resolv.conf as [nameserver 10.0.2.3]"
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.512344260Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.512727579Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.512784807Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.512862051Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.892689262Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.892918142Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.892982021Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:27 minikube dockerd[54451]: time="2023-07-29T02:53:27.893027888Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:28 minikube dockerd[54451]: time="2023-07-29T02:53:28.291381450Z" level=info msg="shim disconnected" id=39d02ef6788701e49ecd6f3da3b47958409a42ea0c5e434922f365c9405b18bb namespace=moby
Jul 29 02:53:28 minikube dockerd[54451]: time="2023-07-29T02:53:28.291964312Z" level=warning msg="cleaning up after shim disconnected" id=39d02ef6788701e49ecd6f3da3b47958409a42ea0c5e434922f365c9405b18bb namespace=moby
Jul 29 02:53:28 minikube dockerd[54451]: time="2023-07-29T02:53:28.292045094Z" level=info msg="cleaning up dead shim" namespace=moby
Jul 29 02:53:28 minikube dockerd[54443]: time="2023-07-29T02:53:28.302204371Z" level=info msg="ignoring event" container=39d02ef6788701e49ecd6f3da3b47958409a42ea0c5e434922f365c9405b18bb module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 29 02:53:28 minikube dockerd[54451]: time="2023-07-29T02:53:28.339178766Z" level=info msg="shim disconnected" id=e628ae206ed4b956041f4fe46d5626ce4e900342a25410c312537e9741ca6e65 namespace=moby
Jul 29 02:53:28 minikube dockerd[54451]: time="2023-07-29T02:53:28.348269581Z" level=warning msg="cleaning up after shim disconnected" id=e628ae206ed4b956041f4fe46d5626ce4e900342a25410c312537e9741ca6e65 namespace=moby
Jul 29 02:53:28 minikube dockerd[54451]: time="2023-07-29T02:53:28.348370721Z" level=info msg="cleaning up dead shim" namespace=moby
Jul 29 02:53:28 minikube dockerd[54443]: time="2023-07-29T02:53:28.527785670Z" level=info msg="ignoring event" container=e628ae206ed4b956041f4fe46d5626ce4e900342a25410c312537e9741ca6e65 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 29 02:53:31 minikube dockerd[54451]: time="2023-07-29T02:53:31.071737915Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:31 minikube dockerd[54451]: time="2023-07-29T02:53:31.072036946Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:31 minikube dockerd[54451]: time="2023-07-29T02:53:31.072059247Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:31 minikube dockerd[54451]: time="2023-07-29T02:53:31.072067979Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.215300049Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.215470193Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.215489149Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.216091118Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.221499855Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.221782934Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.221806787Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:32 minikube dockerd[54451]: time="2023-07-29T02:53:32.221818293Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:44 minikube dockerd[54451]: time="2023-07-29T02:53:44.523963500Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jul 29 02:53:44 minikube dockerd[54451]: time="2023-07-29T02:53:44.524079049Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jul 29 02:53:44 minikube dockerd[54451]: time="2023-07-29T02:53:44.524095222Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jul 29 02:53:44 minikube dockerd[54451]: time="2023-07-29T02:53:44.524106318Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
f4f6606c8e806       6e38f40d628db       25 seconds ago      Running             storage-provisioner       4                   ba2115d33ee77
ca7d5e8c50a21       5a79047369329       37 seconds ago      Running             kube-scheduler            3                   b6764787cbbdf
031f63a08c0ba       fce326961ae2d       37 seconds ago      Running             etcd                      3                   120804b94f851
dd97913a049ce       92ed2bec97a63       39 seconds ago      Running             kube-proxy                3                   79b68e1ba8f84
e480a5067ce18       5185b96f0becf       42 seconds ago      Running             coredns                   2                   c85398f0f5023
e628ae206ed4b       7c5ae0d3388cc       43 seconds ago      Exited              mysql                     15                  925d7899fb55b
39d02ef678870       6e38f40d628db       43 seconds ago      Exited              storage-provisioner       3                   ba2115d33ee77
1596f7d26e446       ce8c2293ef09c       43 seconds ago      Running             kube-controller-manager   4                   a00e7d17af5e8
6189bca762459       1d9b3cbae03ce       43 seconds ago      Running             kube-apiserver            3                   e186b4a454e08
a86181a557708       1d9b3cbae03ce       7 minutes ago       Created             kube-apiserver            2                   5bd2ada1c237f
dfc5c62cc093b       ce8c2293ef09c       7 minutes ago       Created             kube-controller-manager   3                   3aa4f1adf5fb6
af267e31d93ca       5a79047369329       7 minutes ago       Exited              kube-scheduler            2                   21ff409be1fec
d802ecd32c4a0       fce326961ae2d       7 minutes ago       Exited              etcd                      2                   1465b2527420c
4933ee63b249e       92ed2bec97a63       7 minutes ago       Exited              kube-proxy                2                   36db790a02231
152df87c0eb06       5185b96f0becf       23 hours ago        Exited              coredns                   1                   f9a7f2050f2ab
92c78907348d1       ce8c2293ef09c       23 hours ago        Exited              kube-controller-manager   2                   92355eeec7bda
47b0fb5fc0933       ce8c2293ef09c       24 hours ago        Exited              kube-controller-manager   1                   92355eeec7bda

* 
* ==> coredns [152df87c0eb0] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = a4b3afdc4f37ce750a1374aeb332c4f6e1bd6e82f6177e8fdfe3f6144d5dff5e0b01ab4c958d7b8bbdd4f964318fd4569e3b8d84b89e68a866d151681f84459a
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:44727 - 53077 "HINFO IN 7460066510198429642.3104862866157441350. udp 57 false 512" NOERROR qr,rd,ra 57 0.005973873s
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s

* 
* ==> coredns [e480a5067ce1] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = a4b3afdc4f37ce750a1374aeb332c4f6e1bd6e82f6177e8fdfe3f6144d5dff5e0b01ab4c958d7b8bbdd4f964318fd4569e3b8d84b89e68a866d151681f84459a
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:37310 - 13607 "HINFO IN 5830138491017935371.4370278576953971163. udp 57 false 512" NOERROR qr,rd,ra 57 0.001710826s
[INFO] plugin/ready: Still waiting on: "kubernetes"

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=08896fd1dc362c097c925146c4a0d0dac715ace0
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_07_17T20_53_02_0700
                    minikube.k8s.io/version=v1.30.1
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 18 Jul 2023 02:52:58 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sat, 29 Jul 2023 02:54:07 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sat, 29 Jul 2023 02:53:36 +0000   Tue, 18 Jul 2023 02:52:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sat, 29 Jul 2023 02:53:36 +0000   Tue, 18 Jul 2023 02:52:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sat, 29 Jul 2023 02:53:36 +0000   Tue, 18 Jul 2023 02:52:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sat, 29 Jul 2023 02:53:36 +0000   Fri, 28 Jul 2023 03:25:24 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.59.100
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17784752Ki
  hugepages-2Mi:      0
  memory:             3814228Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17784752Ki
  hugepages-2Mi:      0
  memory:             3814228Ki
  pods:               110
System Info:
  Machine ID:                 e2db484e55e84744b86d303ddcca6c1a
  System UUID:                0a56f30c-b06e-c044-8f15-6d92b5a619d9
  Boot ID:                    7b1b1b73-c30f-4c8e-ace2-c701e58db40b
  Kernel Version:             5.10.57
  OS Image:                   Buildroot 2021.02.12
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.23
  Kubelet Version:            v1.26.3
  Kube-Proxy Version:         v1.26.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  default                     mysql8-5c8c4b6bd8-sfr9x             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         23h
  kube-system                 coredns-787d4945fb-hn756            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     11d
  kube-system                 etcd-minikube                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         11d
  kube-system                 kube-apiserver-minikube             250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 kube-controller-manager-minikube    200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 kube-proxy-h47rv                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 kube-scheduler-minikube             100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 storage-provisioner                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (37%!)(MISSING)  0 (0%!)(MISSING)
  memory             170Mi (4%!)(MISSING)  170Mi (4%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type     Reason             Age   From             Message
  ----     ------             ----  ----             -------
  Normal   Starting           32s   kube-proxy       
  Warning  ContainerGCFailed  52s   kubelet          [rpc error: code = Unknown desc = operation timeout: context deadline exceeded, rpc error: code = Unknown desc = Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?]
  Normal   RegisteredNode     21s   node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [  +0.000886] rcu: rcu_sched kthread starved for 52138 jiffies! g499053 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402 ->cpu=1
[  +0.000001] rcu: 	Unless rcu_sched kthread gets sufficient CPU time, OOM is now expected behavior.
[  +0.000000] rcu: RCU grace-period kthread stack dump:
[Jul29 02:53] rcu: INFO: rcu_sched detected stalls on CPUs/tasks:
[  +0.000005] rcu: 	0-...!: (1 ticks this GP) idle=87a/1/0x4000000000000000 softirq=334737/334737 fqs=0 
[  +0.000001] 	(detected by 1, t=315297 jiffies, g=499113, q=788)
[  +0.001115] NMI backtrace for cpu 0
[  +0.000000] CPU: 0 PID: 53904 Comm: containerd-shim Tainted: G        W         5.10.57 #1
[  +0.000001] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
[  +0.000000] RIP: 0010:__pv_queued_spin_lock_slowpath+0xe7/0x2b0
[  +0.000001] Code: 14 41 bd 01 00 00 00 41 be 00 01 00 00 3c 02 0f 94 c0 0f b6 c0 48 89 04 24 c6 43 14 00 ba 00 80 00 00 c6 45 01 01 eb 0b f3 90 <83> ea 01 0f 84 60 01 00 00 0f b6 45 00 84 c0 75 ed 44 89 f0 f0 66
[  +0.000000] RSP: 0000:ffffb10ec0003ef8 EFLAGS: 00010002
[  +0.000001] RAX: 0000000000000001 RBX: ffff96b60fa2ae40 RCX: 0000000000000001
[  +0.000000] RDX: 000000000000777f RSI: 0000000000000000 RDI: 0000000000000000
[  +0.000017] RBP: ffffffffa6740ec0 R08: 0000000000000000 R09: 000003edf105ad82
[  +0.000001] R10: 0000000000000200 R11: ffffffffa66060c0 R12: 0000000000000000
[  +0.000000] R13: 0000000000000001 R14: 0000000000000100 R15: 0000000000040000
[  +0.000000] FS:  000000c000280490(0000) GS:ffff96b60fa00000(0000) knlGS:0000000000000000
[  +0.000015] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[  +0.000001] CR2: 00007f7ab6b04280 CR3: 00000001062f8000 CR4: 00000000000106f0
[  +0.000000] Call Trace:
[  +0.000000]  <IRQ>
[  +0.000000]  _raw_spin_lock_irqsave+0x25/0x30
[  +0.000001]  rcu_core+0x8f/0x610
[  +0.000000]  __do_softirq+0xce/0x27a
[  +0.000000]  asm_call_irq_on_stack+0x12/0x20
[  +0.000000]  </IRQ>
[  +0.000000]  do_softirq_own_stack+0x37/0x40
[  +0.000001]  irq_exit_rcu+0x97/0xa0
[  +0.000000]  sysvec_apic_timer_interrupt+0x36/0x80
[  +0.000000]  ? asm_sysvec_apic_timer_interrupt+0xa/0x20
[  +0.000000]  asm_sysvec_apic_timer_interrupt+0x12/0x20
[  +0.000001] RIP: 0033:0x468256
[  +0.000000] Code: 83 f8 00 74 3e ff d0 48 8b 04 24 48 8b 54 24 08 4c 89 e4 48 8b 4c 24 08 48 89 8b 20 03 00 00 48 8b 0c 24 48 89 8b 28 03 00 00 <48> 69 c0 00 ca 9a 3b 48 01 d0 48 89 44 24 20 48 8b 6c 24 10 48 83
[  +0.000000] RSP: 002b:000000c0000b9dd8 EFLAGS: 00010246
[  +0.000001] RAX: 00000000000010e0 RBX: 000000c000280400 RCX: 0000000000000000
[  +0.000000] RDX: 000000001ce28a62 RSI: 00007ffc3b16b090 RDI: 00007ffc3b16b080
[  +0.000001] RBP: 000000c0000b9de8 R08: 0000000000578c56 R09: 00000000000010e0
[  +0.000000] R10: 00007ffc3b16c000 R11: 000004a8658d22bc R12: 000000c0000b9dd8
[  +0.000000] R13: 0000000000000003 R14: 000000c000282680 R15: 00007f7ab6c9b958
[  +0.000003] rcu: rcu_sched kthread starved for 315297 jiffies! g499113 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402 ->cpu=1
[  +0.000002] rcu: 	Unless rcu_sched kthread gets sufficient CPU time, OOM is now expected behavior.
[  +0.000000] rcu: RCU grace-period kthread stack dump:
[  +0.002005] systemd[1]: systemd-logind.service: Watchdog timeout (limit 3min)!
[  +0.000162] systemd[1]: systemd-networkd.service: Watchdog timeout (limit 3min)!
[  +0.000122] systemd[1]: systemd-resolved.service: Watchdog timeout (limit 3min)!
[  +0.013089] kauditd_printk_skb: 1 callbacks suppressed
[  +0.004903] systemd[1]: systemd-journald.service: Main process exited, code=killed, status=6/ABRT
[  +0.000064] systemd[1]: systemd-journald.service: Failed with result 'watchdog'.
[  +0.015642] systemd[1]: systemd-udevd.service: Main process exited, code=killed, status=6/ABRT
[  +0.000509] systemd[1]: systemd-udevd.service: Failed with result 'watchdog'.
[  +0.013908] systemd[1]: systemd-networkd.service: Main process exited, code=killed, status=6/ABRT
[  +0.000230] systemd[1]: systemd-networkd.service: Failed with result 'watchdog'.
[  +0.016964] systemd[1]: systemd-logind.service: Main process exited, code=killed, status=6/ABRT
[  +0.000325] systemd[1]: systemd-logind.service: Failed with result 'watchdog'.
[  +0.007039] systemd[1]: systemd-resolved.service: Main process exited, code=killed, status=6/ABRT
[  +0.000070] systemd[1]: systemd-resolved.service: Failed with result 'watchdog'.
[  +0.016449] systemd[1]: systemd-journal-flush.service: Failed with result 'exit-code'.
[  +0.518959] systemd-journald[54428]: File /run/log/journal/e2db484e55e84744b86d303ddcca6c1a/system.journal corrupted or uncleanly shut down, renaming and replacing.
[ +18.988873] kauditd_printk_skb: 48 callbacks suppressed

* 
* ==> etcd [031f63a08c0b] <==
* {"level":"info","ts":"2023-07-29T02:53:33.331Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.59.100:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.59.100:2380","--initial-cluster=minikube=https://192.168.59.100:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.59.100:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.59.100:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2023-07-29T02:53:33.331Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/minikube/etcd","dir-type":"member"}
{"level":"info","ts":"2023-07-29T02:53:33.331Z","caller":"embed/etcd.go:124","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.59.100:2380"]}
{"level":"info","ts":"2023-07-29T02:53:33.331Z","caller":"embed/etcd.go:484","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-07-29T02:53:33.331Z","caller":"embed/etcd.go:132","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.59.100:2379"]}
{"level":"info","ts":"2023-07-29T02:53:33.331Z","caller":"embed/etcd.go:306","msg":"starting an etcd server","etcd-version":"3.5.6","git-sha":"cecbe35ce","go-version":"go1.16.15","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.59.100:2380"],"listen-peer-urls":["https://192.168.59.100:2380"],"advertise-client-urls":["https://192.168.59.100:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.59.100:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-07-29T02:53:33.332Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"824.565µs"}
{"level":"info","ts":"2023-07-29T02:53:33.369Z","caller":"etcdserver/server.go:530","msg":"No snapshot found. Recovering WAL from scratch!"}
{"level":"info","ts":"2023-07-29T02:53:33.410Z","caller":"etcdserver/raft.go:529","msg":"restarting local member","cluster-id":"4baf00117c1d04ed","local-member-id":"391c1584d0008f46","commit-index":6176}
{"level":"info","ts":"2023-07-29T02:53:33.410Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 switched to configuration voters=()"}
{"level":"info","ts":"2023-07-29T02:53:33.410Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became follower at term 4"}
{"level":"info","ts":"2023-07-29T02:53:33.410Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft 391c1584d0008f46 [peers: [], term: 4, commit: 6176, applied: 0, lastindex: 6176, lastterm: 4]"}
{"level":"warn","ts":"2023-07-29T02:53:33.414Z","caller":"auth/store.go:1234","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-07-29T02:53:33.421Z","caller":"mvcc/kvstore.go:323","msg":"restored last compact revision","meta-bucket-name":"meta","meta-bucket-name-key":"finishedCompactRev","restored-compact-revision":4502}
{"level":"info","ts":"2023-07-29T02:53:33.423Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":4985}
{"level":"info","ts":"2023-07-29T02:53:33.427Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-07-29T02:53:33.437Z","caller":"etcdserver/corrupt.go:95","msg":"starting initial corruption check","local-member-id":"391c1584d0008f46","timeout":"7s"}
{"level":"info","ts":"2023-07-29T02:53:33.438Z","caller":"etcdserver/corrupt.go:165","msg":"initial corruption checking passed; no corruption","local-member-id":"391c1584d0008f46"}
{"level":"info","ts":"2023-07-29T02:53:33.438Z","caller":"etcdserver/server.go:854","msg":"starting etcd server","local-member-id":"391c1584d0008f46","local-server-version":"3.5.6","cluster-version":"to_be_decided"}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"embed/etcd.go:275","msg":"now serving peer/client/metrics","local-member-id":"391c1584d0008f46","initial-advertise-peer-urls":["https://192.168.59.100:2380"],"listen-peer-urls":["https://192.168.59.100:2380"],"advertise-client-urls":["https://192.168.59.100:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.59.100:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"etcdserver/server.go:754","msg":"starting initial election tick advance","election-ticks":10}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2023-07-29T02:53:33.439Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2023-07-29T02:53:33.440Z","caller":"embed/etcd.go:586","msg":"serving peer traffic","address":"192.168.59.100:2380"}
{"level":"info","ts":"2023-07-29T02:53:33.440Z","caller":"embed/etcd.go:558","msg":"cmux::serve","address":"192.168.59.100:2380"}
{"level":"info","ts":"2023-07-29T02:53:33.440Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 switched to configuration voters=(4115187819679354694)"}
{"level":"info","ts":"2023-07-29T02:53:33.440Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"4baf00117c1d04ed","local-member-id":"391c1584d0008f46","added-peer-id":"391c1584d0008f46","added-peer-peer-urls":["https://192.168.59.100:2380"]}
{"level":"info","ts":"2023-07-29T02:53:33.440Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"4baf00117c1d04ed","local-member-id":"391c1584d0008f46","cluster-version":"3.5"}
{"level":"info","ts":"2023-07-29T02:53:33.440Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 is starting a new election at term 4"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became pre-candidate at term 4"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 received MsgPreVoteResp from 391c1584d0008f46 at term 4"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became candidate at term 5"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 received MsgVoteResp from 391c1584d0008f46 at term 5"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became leader at term 5"}
{"level":"info","ts":"2023-07-29T02:53:34.411Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: 391c1584d0008f46 elected leader 391c1584d0008f46 at term 5"}
{"level":"info","ts":"2023-07-29T02:53:34.418Z","caller":"etcdserver/server.go:2054","msg":"published local member to cluster through raft","local-member-id":"391c1584d0008f46","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.59.100:2379]}","request-path":"/0/members/391c1584d0008f46/attributes","cluster-id":"4baf00117c1d04ed","publish-timeout":"7s"}
{"level":"info","ts":"2023-07-29T02:53:34.418Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-07-29T02:53:34.418Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-07-29T02:53:34.419Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-07-29T02:53:34.419Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"192.168.59.100:2379"}
{"level":"info","ts":"2023-07-29T02:53:34.426Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-07-29T02:53:34.427Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"warn","ts":"2023-07-29T02:53:56.857Z","caller":"etcdserver/v3_server.go:840","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":10324090514215363629,"retry-timeout":"500ms"}
{"level":"info","ts":"2023-07-29T02:53:56.859Z","caller":"traceutil/trace.go:171","msg":"trace[317497856] linearizableReadLoop","detail":"{readStateIndex:6291; appliedIndex:6290; }","duration":"865.430456ms","start":"2023-07-29T02:53:55.993Z","end":"2023-07-29T02:53:56.859Z","steps":["trace[317497856] 'read index received'  (duration: 865.308077ms)","trace[317497856] 'applied index is now lower than readState.Index'  (duration: 122.018µs)"],"step_count":2}
{"level":"warn","ts":"2023-07-29T02:53:56.859Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"865.676895ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-07-29T02:53:56.859Z","caller":"traceutil/trace.go:171","msg":"trace[1537811868] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:5093; }","duration":"865.891581ms","start":"2023-07-29T02:53:55.993Z","end":"2023-07-29T02:53:56.859Z","steps":["trace[1537811868] 'agreement among raft nodes before linearized reading'  (duration: 865.644942ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-29T02:53:56.859Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-29T02:53:55.993Z","time spent":"865.929533ms","remote":"127.0.0.1:37766","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":27,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2023-07-29T02:53:56.859Z","caller":"traceutil/trace.go:171","msg":"trace[137520683] transaction","detail":"{read_only:false; response_revision:5093; number_of_response:1; }","duration":"872.737917ms","start":"2023-07-29T02:53:55.987Z","end":"2023-07-29T02:53:56.859Z","steps":["trace[137520683] 'process raft request'  (duration: 871.971101ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-29T02:53:56.860Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-29T02:53:55.987Z","time spent":"872.780456ms","remote":"127.0.0.1:37650","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":733,"response count":0,"response size":38,"request content":"compare:<target:MOD key:\"/registry/events/kube-system/coredns-787d4945fb-hn756.1776370550f86bee\" mod_revision:5076 > success:<request_put:<key:\"/registry/events/kube-system/coredns-787d4945fb-hn756.1776370550f86bee\" value_size:645 lease:1100718477360587401 >> failure:<request_range:<key:\"/registry/events/kube-system/coredns-787d4945fb-hn756.1776370550f86bee\" > >"}

* 
* ==> etcd [d802ecd32c4a] <==
* {"level":"info","ts":"2023-07-29T02:47:06.401Z","caller":"etcdserver/server.go:530","msg":"No snapshot found. Recovering WAL from scratch!"}
{"level":"info","ts":"2023-07-29T02:47:06.438Z","caller":"etcdserver/raft.go:529","msg":"restarting local member","cluster-id":"4baf00117c1d04ed","local-member-id":"391c1584d0008f46","commit-index":6172}
{"level":"info","ts":"2023-07-29T02:47:06.439Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 switched to configuration voters=()"}
{"level":"info","ts":"2023-07-29T02:47:06.439Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became follower at term 3"}
{"level":"info","ts":"2023-07-29T02:47:06.439Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft 391c1584d0008f46 [peers: [], term: 3, commit: 6172, applied: 0, lastindex: 6172, lastterm: 3]"}
{"level":"warn","ts":"2023-07-29T02:47:06.442Z","caller":"auth/store.go:1234","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-07-29T02:47:06.443Z","caller":"mvcc/kvstore.go:323","msg":"restored last compact revision","meta-bucket-name":"meta","meta-bucket-name-key":"finishedCompactRev","restored-compact-revision":4502}
{"level":"info","ts":"2023-07-29T02:47:06.457Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":4985}
{"level":"info","ts":"2023-07-29T02:47:06.480Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-07-29T02:47:06.483Z","caller":"etcdserver/corrupt.go:95","msg":"starting initial corruption check","local-member-id":"391c1584d0008f46","timeout":"7s"}
{"level":"info","ts":"2023-07-29T02:47:06.484Z","caller":"etcdserver/corrupt.go:165","msg":"initial corruption checking passed; no corruption","local-member-id":"391c1584d0008f46"}
{"level":"info","ts":"2023-07-29T02:47:06.484Z","caller":"etcdserver/server.go:854","msg":"starting etcd server","local-member-id":"391c1584d0008f46","local-server-version":"3.5.6","cluster-version":"to_be_decided"}
{"level":"info","ts":"2023-07-29T02:47:06.486Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-07-29T02:47:06.486Z","caller":"embed/etcd.go:275","msg":"now serving peer/client/metrics","local-member-id":"391c1584d0008f46","initial-advertise-peer-urls":["https://192.168.59.100:2380"],"listen-peer-urls":["https://192.168.59.100:2380"],"advertise-client-urls":["https://192.168.59.100:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.59.100:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-07-29T02:47:06.486Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-07-29T02:47:06.487Z","caller":"etcdserver/server.go:754","msg":"starting initial election tick advance","election-ticks":10}
{"level":"info","ts":"2023-07-29T02:47:06.487Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2023-07-29T02:47:06.487Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2023-07-29T02:47:06.487Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2023-07-29T02:47:06.487Z","caller":"embed/etcd.go:586","msg":"serving peer traffic","address":"192.168.59.100:2380"}
{"level":"info","ts":"2023-07-29T02:47:06.488Z","caller":"embed/etcd.go:558","msg":"cmux::serve","address":"192.168.59.100:2380"}
{"level":"info","ts":"2023-07-29T02:47:06.489Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 switched to configuration voters=(4115187819679354694)"}
{"level":"info","ts":"2023-07-29T02:47:06.489Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"4baf00117c1d04ed","local-member-id":"391c1584d0008f46","added-peer-id":"391c1584d0008f46","added-peer-peer-urls":["https://192.168.59.100:2380"]}
{"level":"info","ts":"2023-07-29T02:47:06.490Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"4baf00117c1d04ed","local-member-id":"391c1584d0008f46","cluster-version":"3.5"}
{"level":"info","ts":"2023-07-29T02:47:06.490Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 is starting a new election at term 3"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became pre-candidate at term 3"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 received MsgPreVoteResp from 391c1584d0008f46 at term 3"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became candidate at term 4"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 received MsgVoteResp from 391c1584d0008f46 at term 4"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"391c1584d0008f46 became leader at term 4"}
{"level":"info","ts":"2023-07-29T02:47:07.946Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: 391c1584d0008f46 elected leader 391c1584d0008f46 at term 4"}
{"level":"info","ts":"2023-07-29T02:47:07.951Z","caller":"etcdserver/server.go:2054","msg":"published local member to cluster through raft","local-member-id":"391c1584d0008f46","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.59.100:2379]}","request-path":"/0/members/391c1584d0008f46/attributes","cluster-id":"4baf00117c1d04ed","publish-timeout":"7s"}
{"level":"info","ts":"2023-07-29T02:47:07.951Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-07-29T02:47:07.964Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-07-29T02:47:07.976Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-07-29T02:47:07.987Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-07-29T02:47:07.987Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"warn","ts":"2023-07-29T02:47:07.988Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37098","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:07.991Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37100","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:07.993Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37102","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:07.995Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37104","server-name":"","error":"EOF"}
{"level":"info","ts":"2023-07-29T02:47:07.999Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"192.168.59.100:2379"}
{"level":"warn","ts":"2023-07-29T02:47:08.010Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37116","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.012Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37108","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.014Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37110","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.016Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37112","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.018Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37114","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.019Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37124","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.021Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37120","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.023Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37122","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.025Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37126","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.027Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37128","server-name":"","error":"EOF"}
{"level":"warn","ts":"2023-07-29T02:47:08.032Z","caller":"embed/config_logging.go:169","msg":"rejected connection","remote-addr":"127.0.0.1:37130","server-name":"","error":"EOF"}
{"level":"info","ts":"2023-07-29T02:53:20.071Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2023-07-29T02:53:20.071Z","caller":"embed/etcd.go:373","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.59.100:2380"],"advertise-client-urls":["https://192.168.59.100:2379"]}
{"level":"info","ts":"2023-07-29T02:53:20.073Z","caller":"etcdserver/server.go:1465","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"391c1584d0008f46","current-leader-member-id":"391c1584d0008f46"}
{"level":"info","ts":"2023-07-29T02:53:20.083Z","caller":"embed/etcd.go:568","msg":"stopping serving peer traffic","address":"192.168.59.100:2380"}
{"level":"info","ts":"2023-07-29T02:53:20.085Z","caller":"embed/etcd.go:573","msg":"stopped serving peer traffic","address":"192.168.59.100:2380"}
{"level":"info","ts":"2023-07-29T02:53:20.085Z","caller":"embed/etcd.go:375","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.59.100:2380"],"advertise-client-urls":["https://192.168.59.100:2379"]}

* 
* ==> kernel <==
*  02:54:10 up  1:12,  0 users,  load average: 20.41, 25.99, 13.60
Linux minikube 5.10.57 #1 SMP Mon Apr 3 23:35:10 UTC 2023 x86_64 GNU/Linux
PRETTY_NAME="Buildroot 2021.02.12"

* 
* ==> kube-apiserver [6189bca76245] <==
* I0729 02:53:36.716043       1 autoregister_controller.go:141] Starting autoregister controller
I0729 02:53:36.716126       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0729 02:53:36.716189       1 apf_controller.go:361] Starting API Priority and Fairness config controller
I0729 02:53:36.717930       1 controller.go:85] Starting OpenAPI controller
I0729 02:53:36.717980       1 controller.go:85] Starting OpenAPI V3 controller
I0729 02:53:36.718135       1 naming_controller.go:291] Starting NamingConditionController
I0729 02:53:36.718158       1 establishing_controller.go:76] Starting EstablishingController
I0729 02:53:36.718172       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0729 02:53:36.718184       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0729 02:53:36.718195       1 crd_finalizer.go:266] Starting CRDFinalizer
I0729 02:53:36.720728       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0729 02:53:36.726146       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0729 02:53:36.726471       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0729 02:53:36.727408       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0729 02:53:36.727438       1 shared_informer.go:273] Waiting for caches to sync for crd-autoregister
I0729 02:53:37.012816       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0729 02:53:37.021219       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0729 02:53:37.040006       1 shared_informer.go:280] Caches are synced for configmaps
I0729 02:53:37.040587       1 shared_informer.go:280] Caches are synced for cluster_authentication_trust_controller
I0729 02:53:37.040860       1 cache.go:39] Caches are synced for autoregister controller
I0729 02:53:37.041336       1 apf_controller.go:366] Running API Priority and Fairness config worker
I0729 02:53:37.041647       1 apf_controller.go:369] Running API Priority and Fairness periodic rebalancing process
I0729 02:53:37.042587       1 shared_informer.go:280] Caches are synced for crd-autoregister
I0729 02:53:37.044014       1 controller.go:615] quota admission added evaluator for: leases.coordination.k8s.io
I0729 02:53:37.097277       1 shared_informer.go:280] Caches are synced for node_authorizer
I0729 02:53:37.386455       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0729 02:53:37.720731       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
E0729 02:53:38.891662       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:38.891571982" prevR="0.03757822ss" incrR="184467440737.09549748ss" currentR="0.03755954ss"
E0729 02:53:38.891905       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:38.891882790" prevR="0.03788429ss" incrR="184467440737.09550220ss" currentR="0.03787033ss"
E0729 02:53:38.892097       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:38.892080762" prevR="0.03814808ss" incrR="184467440737.09549639ss" currentR="0.03812831ss"
E0729 02:53:38.893325       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:38.893306791" prevR="0.03980787ss" incrR="184467440737.09548245ss" currentR="0.03977416ss"
E0729 02:53:49.062485       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.062463733" prevR="0.11899886ss" incrR="184467440737.09551013ss" currentR="0.11899283ss"
E0729 02:53:49.064007       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.063989524" prevR="0.11992367ss" incrR="184467440737.09548323ss" currentR="0.11989074ss"
E0729 02:53:49.066222       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.066056139" prevR="0.12221605ss" incrR="184467440737.09547847ss" currentR="0.12217836ss"
E0729 02:53:49.070302       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.070283449" prevR="0.12736919ss" incrR="184467440737.09547796ss" currentR="0.12733099ss"
E0729 02:53:49.071991       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.071941933" prevR="0.12995939ss" incrR="184467440737.09548776ss" currentR="0.12993099ss"
E0729 02:53:49.119476       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.119440546" prevR="0.16373488ss" incrR="184467440737.09550665ss" currentR="0.16372537ss"
E0729 02:53:49.121756       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.121734594" prevR="0.16605275ss" incrR="184467440737.09548283ss" currentR="0.16601942ss"
E0729 02:53:49.123341       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.123320459" prevR="0.16771502ss" incrR="184467440737.09548066ss" currentR="0.16767952ss"
E0729 02:53:49.124567       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.124546987" prevR="0.16935412ss" incrR="184467440737.09550954ss" currentR="0.16934750ss"
E0729 02:53:49.125895       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.125862779" prevR="0.17078187ss" incrR="184467440737.09548929ss" currentR="0.17075500ss"
E0729 02:53:49.126558       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.126531789" prevR="0.17146114ss" incrR="184467440737.09547903ss" currentR="0.17142401ss"
E0729 02:53:49.306263       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.306232523" prevR="0.23797523ss" incrR="184467440737.09549467ss" currentR="0.23795374ss"
E0729 02:53:49.306874       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.306858585" prevR="0.23861014ss" incrR="184467440737.09548875ss" currentR="0.23858273ss"
E0729 02:53:49.308513       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.308480918" prevR="0.24074219ss" incrR="184467440737.09548382ss" currentR="0.24070985ss"
E0729 02:53:49.309455       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.309424658" prevR="0.24206098ss" incrR="184467440737.09547873ss" currentR="0.24202355ss"
E0729 02:53:49.310551       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.310521038" prevR="0.24373322ss" incrR="184467440737.09546239ss" currentR="0.24367945ss"
E0729 02:53:49.312517       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.312499581" prevR="0.24752981ss" incrR="184467440737.09544434ss" currentR="0.24745799ss"
E0729 02:53:49.335988       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.335966750" prevR="0.27378709ss" incrR="184467440737.09548307ss" currentR="0.27375400ss"
E0729 02:53:49.338645       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.338615235" prevR="0.27500716ss" incrR="184467440737.09550655ss" currentR="0.27499755ss"
I0729 02:53:49.401734       1 controller.go:615] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0729 02:53:49.504116       1 controller.go:615] quota admission added evaluator for: endpoints
E0729 02:53:49.876127       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.876093904" prevR="0.33480570ss" incrR="184467440737.09549037ss" currentR="0.33477991ss"
E0729 02:53:49.904594       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:49.904578031" prevR="0.36311096ss" incrR="184467440737.09550817ss" currentR="0.36310297ss"
E0729 02:53:50.003756       1 queueset.go:461] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2023-07-29 02:53:50.003737533" prevR="0.37370473ss" incrR="184467440737.09548085ss" currentR="0.37366942ss"
I0729 02:53:56.861066       1 trace.go:219] Trace[245641343]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:1e6bd100-d3b2-4cd1-a7db-d2d3e95d17d7,client:192.168.59.100,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/coredns-787d4945fb-hn756.1776370550f86bee,user-agent:kubelet/v1.26.3 (linux/amd64) kubernetes/9e64410,verb:PATCH (29-Jul-2023 02:53:55.978) (total time: 882ms):
Trace[245641343]: ["GuaranteedUpdate etcd3" audit-id:1e6bd100-d3b2-4cd1-a7db-d2d3e95d17d7,key:/events/kube-system/coredns-787d4945fb-hn756.1776370550f86bee,type:*core.Event,resource:events 882ms (02:53:55.978)
Trace[245641343]:  ---"Txn call completed" 874ms (02:53:56.860)]
Trace[245641343]: ---"Object stored in database" 874ms (02:53:56.860)
Trace[245641343]: [882.142803ms] [882.142803ms] END

* 
* ==> kube-apiserver [a86181a55770] <==
* 
* 
* ==> kube-controller-manager [1596f7d26e44] <==
* I0729 02:53:49.256824       1 shared_informer.go:273] Waiting for caches to sync for deployment
I0729 02:53:49.259495       1 controllermanager.go:622] Started "csrapproving"
I0729 02:53:49.259938       1 certificate_controller.go:112] Starting certificate controller "csrapproving"
I0729 02:53:49.259948       1 shared_informer.go:273] Waiting for caches to sync for certificate-csrapproving
E0729 02:53:49.264018       1 core.go:92] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail
W0729 02:53:49.264094       1 controllermanager.go:600] Skipping "service"
I0729 02:53:49.296533       1 controllermanager.go:622] Started "persistentvolume-binder"
I0729 02:53:49.296625       1 pv_controller_base.go:318] Starting persistent volume controller
I0729 02:53:49.299235       1 shared_informer.go:273] Waiting for caches to sync for persistent volume
I0729 02:53:49.303370       1 shared_informer.go:273] Waiting for caches to sync for resource quota
W0729 02:53:49.318807       1 actual_state_of_world.go:541] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I0729 02:53:49.319847       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-serving
I0729 02:53:49.325721       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-legacy-unknown
I0729 02:53:49.325885       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0729 02:53:49.326703       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-client
I0729 02:53:49.333422       1 shared_informer.go:280] Caches are synced for node
I0729 02:53:49.336966       1 shared_informer.go:280] Caches are synced for ClusterRoleAggregator
I0729 02:53:49.337716       1 shared_informer.go:280] Caches are synced for endpoint_slice
I0729 02:53:49.344082       1 range_allocator.go:167] Sending events to api server.
I0729 02:53:49.349935       1 range_allocator.go:171] Starting range CIDR allocator
I0729 02:53:49.350068       1 shared_informer.go:273] Waiting for caches to sync for cidrallocator
I0729 02:53:49.350083       1 shared_informer.go:280] Caches are synced for cidrallocator
I0729 02:53:49.349150       1 shared_informer.go:280] Caches are synced for service account
I0729 02:53:49.352152       1 shared_informer.go:273] Waiting for caches to sync for garbage collector
I0729 02:53:49.359180       1 shared_informer.go:280] Caches are synced for deployment
I0729 02:53:49.360605       1 shared_informer.go:280] Caches are synced for HPA
I0729 02:53:49.362942       1 shared_informer.go:280] Caches are synced for certificate-csrapproving
I0729 02:53:49.367467       1 shared_informer.go:280] Caches are synced for attach detach
I0729 02:53:49.369773       1 shared_informer.go:280] Caches are synced for expand
I0729 02:53:49.370317       1 shared_informer.go:280] Caches are synced for ephemeral
I0729 02:53:49.374408       1 shared_informer.go:280] Caches are synced for PV protection
I0729 02:53:49.377262       1 shared_informer.go:280] Caches are synced for GC
I0729 02:53:49.377435       1 shared_informer.go:280] Caches are synced for namespace
I0729 02:53:49.383269       1 shared_informer.go:280] Caches are synced for PVC protection
I0729 02:53:49.388373       1 shared_informer.go:280] Caches are synced for ReplicationController
I0729 02:53:49.398258       1 shared_informer.go:280] Caches are synced for ReplicaSet
I0729 02:53:49.403700       1 shared_informer.go:280] Caches are synced for disruption
I0729 02:53:49.406969       1 shared_informer.go:280] Caches are synced for endpoint
I0729 02:53:49.411250       1 shared_informer.go:280] Caches are synced for taint
I0729 02:53:49.411464       1 node_lifecycle_controller.go:1438] Initializing eviction metric for zone: 
W0729 02:53:49.411570       1 node_lifecycle_controller.go:1053] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0729 02:53:49.411614       1 node_lifecycle_controller.go:1254] Controller detected that zone  is now in state Normal.
I0729 02:53:49.411700       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0729 02:53:49.412028       1 shared_informer.go:280] Caches are synced for TTL
I0729 02:53:49.412908       1 taint_manager.go:211] "Sending events to api server"
I0729 02:53:49.413020       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0729 02:53:49.429279       1 shared_informer.go:280] Caches are synced for crt configmap
I0729 02:53:49.430413       1 shared_informer.go:280] Caches are synced for bootstrap_signer
I0729 02:53:49.435223       1 shared_informer.go:280] Caches are synced for endpoint_slice_mirroring
I0729 02:53:49.468300       1 shared_informer.go:280] Caches are synced for TTL after finished
I0729 02:53:49.500680       1 shared_informer.go:280] Caches are synced for persistent volume
I0729 02:53:49.504422       1 shared_informer.go:280] Caches are synced for stateful set
I0729 02:53:49.505236       1 shared_informer.go:280] Caches are synced for resource quota
I0729 02:53:49.513663       1 shared_informer.go:280] Caches are synced for cronjob
I0729 02:53:49.860308       1 shared_informer.go:280] Caches are synced for job
I0729 02:53:49.860624       1 shared_informer.go:280] Caches are synced for resource quota
I0729 02:53:49.869298       1 shared_informer.go:280] Caches are synced for daemon sets
I0729 02:53:49.953236       1 shared_informer.go:280] Caches are synced for garbage collector
I0729 02:53:49.991650       1 shared_informer.go:280] Caches are synced for garbage collector
I0729 02:53:49.992177       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage

* 
* ==> kube-controller-manager [47b0fb5fc093] <==
* I0728 03:22:21.482818       1 serving.go:348] Generated self-signed cert in-memory
I0728 03:22:21.937355       1 controllermanager.go:182] Version: v1.26.3
I0728 03:22:21.937515       1 controllermanager.go:184] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0728 03:22:21.950015       1 secure_serving.go:210] Serving securely on 127.0.0.1:10257
I0728 03:22:21.961656       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0728 03:22:21.974822       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0728 03:22:21.974937       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
F0728 03:22:27.170302       1 controllermanager.go:228] error building controller context: failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: an error on the server ("[+]ping ok\n[+]log ok\n[+]etcd ok\n[+]poststarthook/start-kube-apiserver-admission-initializer ok\n[+]poststarthook/generic-apiserver-start-informers ok\n[+]poststarthook/priority-and-fairness-config-consumer ok\n[+]poststarthook/priority-and-fairness-filter ok\n[+]poststarthook/storage-object-count-tracker-hook ok\n[+]poststarthook/start-apiextensions-informers ok\n[+]poststarthook/start-apiextensions-controllers ok\n[+]poststarthook/crd-informer-synced ok\n[+]poststarthook/bootstrap-controller ok\n[-]poststarthook/rbac/bootstrap-roles failed: reason withheld\n[+]poststarthook/scheduling/bootstrap-system-priority-classes ok\n[+]poststarthook/priority-and-fairness-config-producer ok\n[+]poststarthook/start-cluster-authentication-info-controller ok\n[+]poststarthook/start-kube-apiserver-identity-lease-controller ok\n[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok\n[+]poststarthook/start-legacy-token-tracking-controller ok\n[+]poststarthook/aggregator-reload-proxy-client-cert ok\n[+]poststarthook/start-kube-aggregator-informers ok\n[+]poststarthook/apiservice-registration-controller ok\n[+]poststarthook/apiservice-status-available-controller ok\n[+]poststarthook/kube-apiserver-autoregistration ok\n[+]autoregister-completion ok\n[+]poststarthook/apiservice-openapi-controller ok\n[+]poststarthook/apiservice-openapiv3-controller ok\nhealthz check failed") has prevented the request from succeeding

* 
* ==> kube-controller-manager [92c78907348d] <==
* I0728 03:25:28.295304       1 controllermanager.go:622] Started "resourcequota"
I0728 03:25:28.312285       1 controllermanager.go:622] Started "deployment"
I0728 03:25:28.315993       1 deployment_controller.go:154] "Starting controller" controller="deployment"
I0728 03:25:28.318544       1 shared_informer.go:273] Waiting for caches to sync for deployment
I0728 03:25:28.358939       1 shared_informer.go:273] Waiting for caches to sync for resource quota
I0728 03:25:28.362986       1 shared_informer.go:280] Caches are synced for TTL after finished
I0728 03:25:28.364621       1 shared_informer.go:280] Caches are synced for expand
W0728 03:25:28.365886       1 actual_state_of_world.go:541] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I0728 03:25:28.371567       1 shared_informer.go:280] Caches are synced for certificate-csrapproving
I0728 03:25:28.382886       1 shared_informer.go:280] Caches are synced for endpoint_slice_mirroring
I0728 03:25:28.384546       1 shared_informer.go:280] Caches are synced for GC
I0728 03:25:28.389821       1 shared_informer.go:280] Caches are synced for ReplicaSet
I0728 03:25:28.395843       1 shared_informer.go:280] Caches are synced for stateful set
I0728 03:25:28.398944       1 shared_informer.go:273] Waiting for caches to sync for garbage collector
I0728 03:25:28.399372       1 shared_informer.go:280] Caches are synced for ephemeral
I0728 03:25:28.399672       1 shared_informer.go:280] Caches are synced for job
I0728 03:25:28.400168       1 shared_informer.go:280] Caches are synced for ClusterRoleAggregator
I0728 03:25:28.401460       1 shared_informer.go:280] Caches are synced for HPA
I0728 03:25:28.404959       1 shared_informer.go:280] Caches are synced for TTL
I0728 03:25:28.405607       1 shared_informer.go:280] Caches are synced for persistent volume
I0728 03:25:28.413179       1 shared_informer.go:280] Caches are synced for PVC protection
I0728 03:25:28.415740       1 shared_informer.go:280] Caches are synced for PV protection
I0728 03:25:28.420969       1 shared_informer.go:280] Caches are synced for endpoint
I0728 03:25:28.424251       1 shared_informer.go:280] Caches are synced for deployment
I0728 03:25:28.425420       1 shared_informer.go:280] Caches are synced for endpoint_slice
I0728 03:25:28.428676       1 shared_informer.go:280] Caches are synced for node
I0728 03:25:28.428891       1 range_allocator.go:167] Sending events to api server.
I0728 03:25:28.428983       1 range_allocator.go:171] Starting range CIDR allocator
I0728 03:25:28.429016       1 shared_informer.go:273] Waiting for caches to sync for cidrallocator
I0728 03:25:28.429066       1 shared_informer.go:280] Caches are synced for cidrallocator
I0728 03:25:28.438133       1 shared_informer.go:280] Caches are synced for ReplicationController
I0728 03:25:28.442031       1 shared_informer.go:280] Caches are synced for daemon sets
I0728 03:25:28.442351       1 shared_informer.go:280] Caches are synced for disruption
I0728 03:25:28.445783       1 shared_informer.go:280] Caches are synced for bootstrap_signer
I0728 03:25:28.450363       1 shared_informer.go:280] Caches are synced for taint
I0728 03:25:28.450608       1 node_lifecycle_controller.go:1438] Initializing eviction metric for zone: 
I0728 03:25:28.451198       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0728 03:25:28.451495       1 taint_manager.go:211] "Sending events to api server"
I0728 03:25:28.454104       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
W0728 03:25:28.454361       1 node_lifecycle_controller.go:1053] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0728 03:25:28.457112       1 node_lifecycle_controller.go:1254] Controller detected that zone  is now in state Normal.
I0728 03:25:28.454809       1 shared_informer.go:280] Caches are synced for cronjob
I0728 03:25:28.456857       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-client
I0728 03:25:28.456867       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-serving
I0728 03:25:28.460679       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-legacy-unknown
I0728 03:25:28.460691       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0728 03:25:28.460737       1 shared_informer.go:280] Caches are synced for resource quota
I0728 03:25:28.495674       1 shared_informer.go:280] Caches are synced for resource quota
I0728 03:25:28.527557       1 shared_informer.go:280] Caches are synced for crt configmap
I0728 03:25:28.538917       1 shared_informer.go:280] Caches are synced for attach detach
I0728 03:25:28.548232       1 shared_informer.go:280] Caches are synced for service account
I0728 03:25:28.571286       1 shared_informer.go:280] Caches are synced for namespace
I0728 03:25:28.935664       1 shared_informer.go:280] Caches are synced for garbage collector
I0728 03:25:28.937508       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0728 03:25:29.000460       1 shared_informer.go:280] Caches are synced for garbage collector
I0728 03:44:02.634515       1 event.go:294] "Event occurred" object="default/mysql8" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set mysql8-5c8c4b6bd8 to 1"
I0728 03:44:02.650377       1 event.go:294] "Event occurred" object="default/mysql8-5c8c4b6bd8" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: mysql8-5c8c4b6bd8-sfr9x"
I0728 04:25:28.194091       1 cleaner.go:172] Cleaning CSR "csr-cm85h" as it is more than 1h0m0s old and approved.
E0729 02:46:57.736190       1 resource_quota_controller.go:417] failed to discover resources: the server has asked for the client to provide credentials
W0729 02:46:59.557869       1 garbagecollector.go:754] failed to discover preferred resources: the server has asked for the client to provide credentials

* 
* ==> kube-controller-manager [dfc5c62cc093] <==
* 
* 
* ==> kube-proxy [4933ee63b249] <==
* E0729 02:47:06.365724       1 node.go:152] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:47:07.509430       1 node.go:152] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:47:09.884744       1 node.go:152] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:17.901072       1 node.go:152] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.59.100:8443: connect: connection refused

* 
* ==> kube-proxy [dd97913a049c] <==
* I0729 02:53:37.006332       1 node.go:163] Successfully retrieved node IP: 192.168.59.100
I0729 02:53:37.006561       1 server_others.go:109] "Detected node IP" address="192.168.59.100"
I0729 02:53:37.006634       1 server_others.go:535] "Using iptables proxy"
I0729 02:53:37.261020       1 server_others.go:170] "kube-proxy running in single-stack mode, this ipFamily is not supported" ipFamily=IPv6
I0729 02:53:37.261099       1 server_others.go:176] "Using iptables Proxier"
I0729 02:53:37.261370       1 proxier.go:242] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0729 02:53:37.262800       1 server.go:655] "Version info" version="v1.26.3"
I0729 02:53:37.263140       1 server.go:657] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0729 02:53:37.266208       1 config.go:317] "Starting service config controller"
I0729 02:53:37.266623       1 shared_informer.go:273] Waiting for caches to sync for service config
I0729 02:53:37.266907       1 config.go:226] "Starting endpoint slice config controller"
I0729 02:53:37.267254       1 shared_informer.go:273] Waiting for caches to sync for endpoint slice config
I0729 02:53:37.270667       1 config.go:444] "Starting node config controller"
I0729 02:53:37.270887       1 shared_informer.go:273] Waiting for caches to sync for node config
I0729 02:53:37.367557       1 shared_informer.go:280] Caches are synced for service config
I0729 02:53:37.367569       1 shared_informer.go:280] Caches are synced for endpoint slice config
I0729 02:53:37.371308       1 shared_informer.go:280] Caches are synced for node config

* 
* ==> kube-scheduler [af267e31d93c] <==
* E0729 02:52:23.975377       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.975435       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.975457       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.975502       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.59.100:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.975519       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.59.100:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.975563       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.975580       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.975630       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.59.100:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.975650       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.59.100:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.976528       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.59.100:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.976625       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.59.100:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.976720       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.59.100:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.976749       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.59.100:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.976810       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.976830       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.976884       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://192.168.59.100:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.976922       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.59.100:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.976955       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.59.100:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.976970       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.59.100:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.976982       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.977001       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.977515       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.59.100:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.977560       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.59.100:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:52:23.980592       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.59.100:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:52:23.980635       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.59.100:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:18.720135       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:18.720172       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:18.736168       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://192.168.59.100:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:18.736674       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.59.100:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:18.967355       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.59.100:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:18.967386       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.59.100:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.036731       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.59.100:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.036772       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.59.100:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.068832       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://192.168.59.100:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.068862       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.59.100:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.103077       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.59.100:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.103109       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.59.100:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.128113       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.59.100:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.128144       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.59.100:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.220077       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.220115       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.228748       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.59.100:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.228797       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.59.100:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.279000       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.279031       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.376826       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.59.100:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.377407       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.59.100:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.449979       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.59.100:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.450009       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.59.100:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.463231       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.463263       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.469021       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.469052       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.59.100:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
W0729 02:53:19.507030       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.59.100:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
E0729 02:53:19.507068       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.59.100:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.59.100:8443: connect: connection refused
I0729 02:53:20.006270       1 secure_serving.go:255] Stopped listening on 127.0.0.1:10259
I0729 02:53:20.006306       1 tlsconfig.go:255] "Shutting down DynamicServingCertificateController"
E0729 02:53:20.006332       1 shared_informer.go:276] unable to sync caches for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0729 02:53:20.006339       1 configmap_cafile_content.go:210] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
E0729 02:53:20.006538       1 run.go:74] "command failed" err="finished without leader elect"

* 
* ==> kube-scheduler [ca7d5e8c50a2] <==
* I0729 02:53:33.951739       1 serving.go:348] Generated self-signed cert in-memory
W0729 02:53:36.881295       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0729 02:53:36.882223       1 authentication.go:349] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0729 02:53:36.882334       1 authentication.go:350] Continuing without authentication configuration. This may treat all requests as anonymous.
W0729 02:53:36.882371       1 authentication.go:351] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0729 02:53:36.933023       1 server.go:152] "Starting Kubernetes Scheduler" version="v1.26.3"
I0729 02:53:36.943641       1 server.go:154] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0729 02:53:36.944685       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0729 02:53:36.944802       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0729 02:53:36.946377       1 shared_informer.go:273] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0729 02:53:36.944819       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0729 02:53:36.982285       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0729 02:53:36.982399       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0729 02:53:36.982488       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0729 02:53:36.982501       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0729 02:53:36.982588       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0729 02:53:36.982810       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0729 02:53:36.982986       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0729 02:53:36.982999       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0729 02:53:36.983090       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0729 02:53:36.983188       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0729 02:53:36.983246       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0729 02:53:36.983254       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0729 02:53:36.983337       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0729 02:53:36.983488       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0729 02:53:36.983670       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0729 02:53:36.983682       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0729 02:53:36.986218       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0729 02:53:36.986324       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0729 02:53:36.986481       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0729 02:53:36.986632       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0729 02:53:36.986725       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0729 02:53:36.986739       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0729 02:53:36.986831       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0729 02:53:36.987046       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0729 02:53:36.987153       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0729 02:53:36.987234       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0729 02:53:36.987308       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0729 02:53:36.987319       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0729 02:53:36.987546       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0729 02:53:36.990968       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
I0729 02:53:38.350962       1 shared_informer.go:280] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* -- Journal begins at Fri 2023-07-28 03:21:43 UTC, ends at Sat 2023-07-29 02:54:11 UTC. --
Jul 29 02:53:30 minikube kubelet[1378]: E0729 02:53:30.887617    1378 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(beed8d03-4953-45f6-ba0d-e66a8c57c1e9)\"" pod="kube-system/storage-provisioner" podUID=beed8d03-4953-45f6-ba0d-e66a8c57c1e9
Jul 29 02:53:30 minikube kubelet[1378]: I0729 02:53:30.899553    1378 scope.go:115] "RemoveContainer" containerID="24f863fa44c498a0e22b6431aa67fe1b3f5844d3523e673b70572cf605b0097c"
Jul 29 02:53:30 minikube kubelet[1378]: I0729 02:53:30.948697    1378 scope.go:115] "RemoveContainer" containerID="4933ee63b249e14169a31491ce472ed6cac36e64706ab3272f8005dd16cfc571"
Jul 29 02:53:31 minikube kubelet[1378]: I0729 02:53:31.976717    1378 scope.go:115] "RemoveContainer" containerID="39d02ef6788701e49ecd6f3da3b47958409a42ea0c5e434922f365c9405b18bb"
Jul 29 02:53:31 minikube kubelet[1378]: E0729 02:53:31.977152    1378 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(beed8d03-4953-45f6-ba0d-e66a8c57c1e9)\"" pod="kube-system/storage-provisioner" podUID=beed8d03-4953-45f6-ba0d-e66a8c57c1e9
Jul 29 02:53:32 minikube kubelet[1378]: I0729 02:53:32.040318    1378 scope.go:115] "RemoveContainer" containerID="d802ecd32c4a09c21a011b0e9c2faf0116cc443adf4896d067207daede7984ef"
Jul 29 02:53:32 minikube kubelet[1378]: I0729 02:53:32.040515    1378 scope.go:115] "RemoveContainer" containerID="e628ae206ed4b956041f4fe46d5626ce4e900342a25410c312537e9741ca6e65"
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.040623    1378 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=mysql pod=mysql8-5c8c4b6bd8-sfr9x_default(3555a69d-9136-4ff3-9286-e3a5204e2227)\"" pod="default/mysql8-5c8c4b6bd8-sfr9x" podUID=3555a69d-9136-4ff3-9286-e3a5204e2227
Jul 29 02:53:32 minikube kubelet[1378]: I0729 02:53:32.040789    1378 scope.go:115] "RemoveContainer" containerID="af267e31d93ca0a0463006202936e42e0c18601915a0f99379a4daa3b2b4583f"
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.870514    1378 configmap.go:199] Couldn't get configMap kube-system/kube-proxy: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.870828    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/configmap/52faf475-6b56-4bcb-a806-33a347c22f16-kube-proxy podName:52faf475-6b56-4bcb-a806-33a347c22f16 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:36.870810779 +0000 UTC m=+4284.309061521 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "kube-proxy" (UniqueName: "kubernetes.io/configmap/52faf475-6b56-4bcb-a806-33a347c22f16-kube-proxy") pod "kube-proxy-h47rv" (UID: "52faf475-6b56-4bcb-a806-33a347c22f16") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872393    1378 configmap.go:199] Couldn't get configMap kube-system/coredns: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872474    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/configmap/9c17e326-4480-496d-aaf0-ff2928f39bd7-config-volume podName:9c17e326-4480-496d-aaf0-ff2928f39bd7 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:36.872459059 +0000 UTC m=+4284.310709802 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "config-volume" (UniqueName: "kubernetes.io/configmap/9c17e326-4480-496d-aaf0-ff2928f39bd7-config-volume") pod "coredns-787d4945fb-hn756" (UID: "9c17e326-4480-496d-aaf0-ff2928f39bd7") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872496    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872508    1378 projected.go:198] Error preparing data for projected volume kube-api-access-8zmbf for pod kube-system/kube-proxy-h47rv: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872528    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/52faf475-6b56-4bcb-a806-33a347c22f16-kube-api-access-8zmbf podName:52faf475-6b56-4bcb-a806-33a347c22f16 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:36.872522134 +0000 UTC m=+4284.310772878 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "kube-api-access-8zmbf" (UniqueName: "kubernetes.io/projected/52faf475-6b56-4bcb-a806-33a347c22f16-kube-api-access-8zmbf") pod "kube-proxy-h47rv" (UID: "52faf475-6b56-4bcb-a806-33a347c22f16") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872541    1378 projected.go:292] Couldn't get configMap default/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872548    1378 projected.go:198] Error preparing data for projected volume kube-api-access-6whn8 for pod default/mysql8-5c8c4b6bd8-sfr9x: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:32 minikube kubelet[1378]: E0729 02:53:32.872568    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/3555a69d-9136-4ff3-9286-e3a5204e2227-kube-api-access-6whn8 podName:3555a69d-9136-4ff3-9286-e3a5204e2227 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:36.872562411 +0000 UTC m=+4284.310813153 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "kube-api-access-6whn8" (UniqueName: "kubernetes.io/projected/3555a69d-9136-4ff3-9286-e3a5204e2227-kube-api-access-6whn8") pod "mysql8-5c8c4b6bd8-sfr9x" (UID: "3555a69d-9136-4ff3-9286-e3a5204e2227") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:36 minikube kubelet[1378]: W0729 02:53:36.781871    1378 reflector.go:424] object-"kube-system"/"kube-root-ca.crt": failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: E0729 02:53:36.782251    1378 reflector.go:140] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: W0729 02:53:36.782381    1378 reflector.go:424] object-"default"/"kube-root-ca.crt": failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "default": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: E0729 02:53:36.782477    1378 reflector.go:140] object-"default"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "default": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: W0729 02:53:36.782550    1378 reflector.go:424] object-"kube-system"/"coredns": failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: E0729 02:53:36.782585    1378 reflector.go:140] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: W0729 02:53:36.782630    1378 reflector.go:424] object-"kube-system"/"kube-proxy": failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object
Jul 29 02:53:36 minikube kubelet[1378]: E0729 02:53:36.782662    1378 reflector.go:140] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "kube-proxy" is forbidden: User "system:node:minikube" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.782935    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.783160    1378 projected.go:198] Error preparing data for projected volume kube-api-access-fmflc for pod kube-system/storage-provisioner: [failed to fetch token: serviceaccounts "storage-provisioner" is forbidden: User "system:node:minikube" cannot create resource "serviceaccounts/token" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object, failed to sync configmap cache: timed out waiting for the condition]
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.783251    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/beed8d03-4953-45f6-ba0d-e66a8c57c1e9-kube-api-access-fmflc podName:beed8d03-4953-45f6-ba0d-e66a8c57c1e9 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:53.783233504 +0000 UTC m=+4301.221484247 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "kube-api-access-fmflc" (UniqueName: "kubernetes.io/projected/beed8d03-4953-45f6-ba0d-e66a8c57c1e9-kube-api-access-fmflc") pod "storage-provisioner" (UID: "beed8d03-4953-45f6-ba0d-e66a8c57c1e9") : [failed to fetch token: serviceaccounts "storage-provisioner" is forbidden: User "system:node:minikube" cannot create resource "serviceaccounts/token" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object, failed to sync configmap cache: timed out waiting for the condition]
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.783279    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.783289    1378 projected.go:198] Error preparing data for projected volume kube-api-access-zg9s4 for pod kube-system/coredns-787d4945fb-hn756: [failed to fetch token: serviceaccounts "coredns" is forbidden: User "system:node:minikube" cannot create resource "serviceaccounts/token" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object, failed to sync configmap cache: timed out waiting for the condition]
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.783309    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/9c17e326-4480-496d-aaf0-ff2928f39bd7-kube-api-access-zg9s4 podName:9c17e326-4480-496d-aaf0-ff2928f39bd7 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:39.783304011 +0000 UTC m=+4287.221554754 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "kube-api-access-zg9s4" (UniqueName: "kubernetes.io/projected/9c17e326-4480-496d-aaf0-ff2928f39bd7-kube-api-access-zg9s4") pod "coredns-787d4945fb-hn756" (UID: "9c17e326-4480-496d-aaf0-ff2928f39bd7") : [failed to fetch token: serviceaccounts "coredns" is forbidden: User "system:node:minikube" cannot create resource "serviceaccounts/token" in API group "" in the namespace "kube-system": no relationship found between node 'minikube' and this object, failed to sync configmap cache: timed out waiting for the condition]
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904481    1378 configmap.go:199] Couldn't get configMap kube-system/kube-proxy: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904723    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/configmap/52faf475-6b56-4bcb-a806-33a347c22f16-kube-proxy podName:52faf475-6b56-4bcb-a806-33a347c22f16 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:45.904701686 +0000 UTC m=+4293.342952449 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "kube-proxy" (UniqueName: "kubernetes.io/configmap/52faf475-6b56-4bcb-a806-33a347c22f16-kube-proxy") pod "kube-proxy-h47rv" (UID: "52faf475-6b56-4bcb-a806-33a347c22f16") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904871    1378 configmap.go:199] Couldn't get configMap kube-system/coredns: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904902    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/configmap/9c17e326-4480-496d-aaf0-ff2928f39bd7-config-volume podName:9c17e326-4480-496d-aaf0-ff2928f39bd7 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:45.904894812 +0000 UTC m=+4293.343145555 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "config-volume" (UniqueName: "kubernetes.io/configmap/9c17e326-4480-496d-aaf0-ff2928f39bd7-config-volume") pod "coredns-787d4945fb-hn756" (UID: "9c17e326-4480-496d-aaf0-ff2928f39bd7") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904918    1378 projected.go:292] Couldn't get configMap default/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904929    1378 projected.go:198] Error preparing data for projected volume kube-api-access-6whn8 for pod default/mysql8-5c8c4b6bd8-sfr9x: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.904952    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/3555a69d-9136-4ff3-9286-e3a5204e2227-kube-api-access-6whn8 podName:3555a69d-9136-4ff3-9286-e3a5204e2227 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:45.90494479 +0000 UTC m=+4293.343195544 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "kube-api-access-6whn8" (UniqueName: "kubernetes.io/projected/3555a69d-9136-4ff3-9286-e3a5204e2227-kube-api-access-6whn8") pod "mysql8-5c8c4b6bd8-sfr9x" (UID: "3555a69d-9136-4ff3-9286-e3a5204e2227") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.905066    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.905081    1378 projected.go:198] Error preparing data for projected volume kube-api-access-8zmbf for pod kube-system/kube-proxy-h47rv: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:37 minikube kubelet[1378]: E0729 02:53:37.905105    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/52faf475-6b56-4bcb-a806-33a347c22f16-kube-api-access-8zmbf podName:52faf475-6b56-4bcb-a806-33a347c22f16 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:45.905097781 +0000 UTC m=+4293.343348523 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "kube-api-access-8zmbf" (UniqueName: "kubernetes.io/projected/52faf475-6b56-4bcb-a806-33a347c22f16-kube-api-access-8zmbf") pod "kube-proxy-h47rv" (UID: "52faf475-6b56-4bcb-a806-33a347c22f16") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:41 minikube kubelet[1378]: E0729 02:53:41.085772    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:41 minikube kubelet[1378]: E0729 02:53:41.086406    1378 projected.go:198] Error preparing data for projected volume kube-api-access-zg9s4 for pod kube-system/coredns-787d4945fb-hn756: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:41 minikube kubelet[1378]: E0729 02:53:41.086514    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/9c17e326-4480-496d-aaf0-ff2928f39bd7-kube-api-access-zg9s4 podName:9c17e326-4480-496d-aaf0-ff2928f39bd7 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:45.086492464 +0000 UTC m=+4292.524743206 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "kube-api-access-zg9s4" (UniqueName: "kubernetes.io/projected/9c17e326-4480-496d-aaf0-ff2928f39bd7-kube-api-access-zg9s4") pod "coredns-787d4945fb-hn756" (UID: "9c17e326-4480-496d-aaf0-ff2928f39bd7") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:44 minikube kubelet[1378]: I0729 02:53:44.405165    1378 scope.go:115] "RemoveContainer" containerID="39d02ef6788701e49ecd6f3da3b47958409a42ea0c5e434922f365c9405b18bb"
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.103357    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.103397    1378 projected.go:198] Error preparing data for projected volume kube-api-access-zg9s4 for pod kube-system/coredns-787d4945fb-hn756: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.103453    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/9c17e326-4480-496d-aaf0-ff2928f39bd7-kube-api-access-zg9s4 podName:9c17e326-4480-496d-aaf0-ff2928f39bd7 nodeName:}" failed. No retries permitted until 2023-07-29 02:53:54.103436586 +0000 UTC m=+4301.541687339 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "kube-api-access-zg9s4" (UniqueName: "kubernetes.io/projected/9c17e326-4480-496d-aaf0-ff2928f39bd7-kube-api-access-zg9s4") pod "coredns-787d4945fb-hn756" (UID: "9c17e326-4480-496d-aaf0-ff2928f39bd7") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.909862    1378 projected.go:292] Couldn't get configMap kube-system/kube-root-ca.crt: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.909962    1378 projected.go:198] Error preparing data for projected volume kube-api-access-8zmbf for pod kube-system/kube-proxy-h47rv: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.910025    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/52faf475-6b56-4bcb-a806-33a347c22f16-kube-api-access-8zmbf podName:52faf475-6b56-4bcb-a806-33a347c22f16 nodeName:}" failed. No retries permitted until 2023-07-29 02:54:02.910008876 +0000 UTC m=+4310.348259619 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "kube-api-access-8zmbf" (UniqueName: "kubernetes.io/projected/52faf475-6b56-4bcb-a806-33a347c22f16-kube-api-access-8zmbf") pod "kube-proxy-h47rv" (UID: "52faf475-6b56-4bcb-a806-33a347c22f16") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.909860    1378 configmap.go:199] Couldn't get configMap kube-system/kube-proxy: failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:46 minikube kubelet[1378]: E0729 02:53:46.910054    1378 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/configmap/52faf475-6b56-4bcb-a806-33a347c22f16-kube-proxy podName:52faf475-6b56-4bcb-a806-33a347c22f16 nodeName:}" failed. No retries permitted until 2023-07-29 02:54:02.910048611 +0000 UTC m=+4310.348299354 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "kube-proxy" (UniqueName: "kubernetes.io/configmap/52faf475-6b56-4bcb-a806-33a347c22f16-kube-proxy") pod "kube-proxy-h47rv" (UID: "52faf475-6b56-4bcb-a806-33a347c22f16") : failed to sync configmap cache: timed out waiting for the condition
Jul 29 02:53:47 minikube kubelet[1378]: I0729 02:53:47.404334    1378 scope.go:115] "RemoveContainer" containerID="e628ae206ed4b956041f4fe46d5626ce4e900342a25410c312537e9741ca6e65"
Jul 29 02:53:47 minikube kubelet[1378]: E0729 02:53:47.407361    1378 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=mysql pod=mysql8-5c8c4b6bd8-sfr9x_default(3555a69d-9136-4ff3-9286-e3a5204e2227)\"" pod="default/mysql8-5c8c4b6bd8-sfr9x" podUID=3555a69d-9136-4ff3-9286-e3a5204e2227
Jul 29 02:53:55 minikube kubelet[1378]: I0729 02:53:55.976032    1378 request.go:690] Waited for 1.027396693s due to client-side throttling, not priority and fairness, request: PATCH:https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/events/coredns-787d4945fb-hn756.1776370550f86bee
Jul 29 02:54:01 minikube kubelet[1378]: I0729 02:54:01.405655    1378 scope.go:115] "RemoveContainer" containerID="e628ae206ed4b956041f4fe46d5626ce4e900342a25410c312537e9741ca6e65"
Jul 29 02:54:01 minikube kubelet[1378]: E0729 02:54:01.406039    1378 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=mysql pod=mysql8-5c8c4b6bd8-sfr9x_default(3555a69d-9136-4ff3-9286-e3a5204e2227)\"" pod="default/mysql8-5c8c4b6bd8-sfr9x" podUID=3555a69d-9136-4ff3-9286-e3a5204e2227

* 
* ==> storage-provisioner [39d02ef67887] <==
* I0729 02:53:27.812513       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0729 02:53:27.848598       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: connect: connection refused

* 
* ==> storage-provisioner [f4f6606c8e80] <==
* I0729 02:53:44.706743       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0729 02:53:44.760790       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0729 02:53:44.764132       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0729 02:53:59.940452       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0729 02:53:59.941487       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_6cafeafc-76a4-4a65-9523-2372a8cc1e73!
I0729 02:53:59.945122       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"394a7706-e3b7-41ad-bcd6-0e1f68728a89", APIVersion:"v1", ResourceVersion:"5116", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_6cafeafc-76a4-4a65-9523-2372a8cc1e73 became leader
I0729 02:54:00.042880       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_6cafeafc-76a4-4a65-9523-2372a8cc1e73!

